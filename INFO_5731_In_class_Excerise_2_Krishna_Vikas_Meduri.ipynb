{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INFO 5731 In-class Excerise 2- Krishna Vikas Meduri",
      "provenance": [],
      "authorship_tag": "ABX9TyNmTFRrmIPKwmsQycTlCEMl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishnavikas-7/INFO-5731/blob/main/INFO_5731_In_class_Excerise_2_Krishna_Vikas_Meduri.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynZiTxMuc9Ug"
      },
      "source": [
        "## **The third In-class-exercise (9/15/2021, 40 points in total)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zQogfXwdIas"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiHEK98QdL_U"
      },
      "source": [
        "##**Question 1:** (10 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McNfdntbdQc8"
      },
      "source": [
        "## **Answer:**\n",
        "Research question - What is the review of Witcher 3 wild hunt video game. Whether it has positive reviews or negative reviews.\n",
        "Data required for this research is reviews of the customer who already bought the game. Ecommerce website contains the reviews of the product. I have choosen the amazon service to\n",
        "collect the reviews of the Witcher 3 wild hunt video game. We can analyze the reviews by considering the words in them that is whether the user customer has written in a positive way\n",
        "or negative way. We need minimum 500 reviews to get nearly accurate results.\n",
        "\n",
        "Steps for Collecting and Saving Data:\n",
        "I have used the BeautifulSoup library to extract the information from the website.\n",
        "I have extracted the reviews by using the classname and then appended to the empty list.\n",
        "To extract 500 reviews I have itearted 50 times as each page contains 10 reviews and I have generated the url dynamically while iterating\n",
        "Then created a dataframe form the list and then converted dataframe to csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbiA_j4gdalL"
      },
      "source": [
        "##**Question 2:** (10 points): Write python code to collect 1000 reviews of a movie from IMDB (https://www.imdb.com/) or 1000 reviews of a product from Amazon (https://www.amazon.com/).\n",
        "\n",
        "As for the IMDB movie review, the following informtion need to be collected (for example: https://www.imdb.com/title/tt6751668/reviews?ref_=tt_urv):\n",
        "\n",
        "(1) User name\n",
        "\n",
        "(2) Star\n",
        "\n",
        "(3) Review title\n",
        "\n",
        "(4) Review text\n",
        "\n",
        "(5) Review posted time\n",
        "\n",
        "As for the Amazon product review, the following information need to be collected (for example: https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1492032646/ref=sr_1_3?crid=2E3C55VKJX0K3&dchild=1&keywords=machine+learning+andrew+ng&qid=1631718619&sr=8-3):\n",
        "\n",
        "(1) User name\n",
        "\n",
        "(2) Star\n",
        "\n",
        "(3) Review title\n",
        "\n",
        "(4) Review text\n",
        "\n",
        "(5) Review posted time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kng0XTtKZUd",
        "outputId": "5b71dbb0-7f22-4563-ba3d-3ebdb05f327c"
      },
      "source": [
        "! pip install selenium"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 24.2 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 92 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 307 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 317 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 327 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 337 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 348 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 358 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 368 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 378 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 389 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 399 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 409 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 419 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 430 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 440 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 450 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 460 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 471 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 481 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 491 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 501 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 512 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 522 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 532 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 542 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 552 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 563 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 573 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 583 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 593 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 604 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 614 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 624 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 634 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 645 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 655 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 665 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 675 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 686 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 696 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 706 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 716 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 727 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 737 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 747 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 757 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 768 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 778 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 788 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 798 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 808 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 819 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 829 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 839 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 849 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 860 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 870 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 880 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 890 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 901 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 904 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnjSSZufKU74"
      },
      "source": [
        "from selenium import webdriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('-headless')\n",
        "options.add_argument('-no-sandbox')\n",
        "options.add_argument('-disable-dev-shm-usage')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYzVAiDtKkSI",
        "outputId": "a82c7f39-4ba9-444b-e87b-4cfc8de85dd5"
      },
      "source": [
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 14.2 kB/88.7\r0% [Waiting for headers] [Connected to cloud.r-project.org (65.8.185.73)] [Wait\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [3 InRelease 3,626 B/3,626 \r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r                                                                               \r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers]\r                                                                         \rHit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,428 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,326 kB]\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:15 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [67.4 kB]\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,802 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,761 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [922 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,202 kB]\n",
            "Fetched 11.8 MB in 3s (3,482 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 56 not upgraded.\n",
            "Need to get 91.8 MB of archives.\n",
            "After this operation, 315 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 92.0.4515.159-0ubuntu0.18.04.1 [1,124 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 92.0.4515.159-0ubuntu0.18.04.1 [81.7 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 92.0.4515.159-0ubuntu0.18.04.1 [4,026 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 92.0.4515.159-0ubuntu0.18.04.1 [4,902 kB]\n",
            "Fetched 91.8 MB in 4s (23.9 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 155013 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_92.0.4515.159-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (92.0.4515.159-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_92.0.4515.159-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (92.0.4515.159-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_92.0.4515.159-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (92.0.4515.159-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_92.0.4515.159-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (92.0.4515.159-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (92.0.4515.159-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (92.0.4515.159-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (92.0.4515.159-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (92.0.4515.159-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "JC-jxguyKfe-",
        "outputId": "7c3b7178-e5fc-4116-ca63-a80f4acb7b24"
      },
      "source": [
        "from selenium.webdriver.support.ui import WebDriverWait as wait\n",
        "from selenium.webdriver.common.by import By\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "driver = webdriver.Chrome('chromedriver',options=options)\n",
        "link = 'https://www.imdb.com/title/tt0111161/reviews'\n",
        "title_array = []\n",
        "review_array = []\n",
        "driver.get(link)\n",
        "for num in range(43):\n",
        "  driver.find_element_by_class_name(\"ipl-load-more__button\").click()\n",
        "  time.sleep(5)\n",
        "  listOfTitle = driver.find_elements(By.CLASS_NAME, \"title\")\n",
        "  listOfReviews = driver.find_elements(By.CLASS_NAME, \"text\")\n",
        "for ele, sub_ele in zip(listOfTitle, listOfReviews):\n",
        "      title_array.append((ele.text).replace('\\n',''))\n",
        "      review_array.append(sub_ele.text)\n",
        "df = pd.DataFrame(list(zip(title_array, review_array)), columns =['Title', 'Review'])\n",
        "print(\"Length of data frame is {0}\".format(len(df)))\n",
        "df\n",
        "  "
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of data frame is 1098\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tied for the best movie I have ever seen</td>\n",
              "      <td>Why do I want to write the 234th comment on Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Some birds aren't meant to be caged.</td>\n",
              "      <td>The Shawshank Redemption is written and direct...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A classic piece of unforgettable film-making.</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Prepare to be moved</td>\n",
              "      <td>I have never seen such an amazing film since I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Shawshank Redeems Hollywood</td>\n",
              "      <td>Can Hollywood, usually creating things for ent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1093</th>\n",
              "      <td>The best movie made to date.</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1094</th>\n",
              "      <td>The best movie ever</td>\n",
              "      <td>This movie doesn't deserve a 10, it deserves a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>My all time favourite film. Beautiful.</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1096</th>\n",
              "      <td>One of the greatest films ever made.</td>\n",
              "      <td>Whenever I see a prison or even think about it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1097</th>\n",
              "      <td>Great among greats.</td>\n",
              "      <td>I have three framed posters of my favourite fi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1098 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Title                                             Review\n",
              "0          Tied for the best movie I have ever seen  Why do I want to write the 234th comment on Th...\n",
              "1              Some birds aren't meant to be caged.  The Shawshank Redemption is written and direct...\n",
              "2     A classic piece of unforgettable film-making.                                                   \n",
              "3                               Prepare to be moved  I have never seen such an amazing film since I...\n",
              "4                       Shawshank Redeems Hollywood  Can Hollywood, usually creating things for ent...\n",
              "...                                             ...                                                ...\n",
              "1093                   The best movie made to date.                                                   \n",
              "1094                            The best movie ever  This movie doesn't deserve a 10, it deserves a...\n",
              "1095         My all time favourite film. Beautiful.                                                   \n",
              "1096           One of the greatest films ever made.  Whenever I see a prison or even think about it...\n",
              "1097                            Great among greats.  I have three framed posters of my favourite fi...\n",
              "\n",
              "[1098 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCsCgxQxfl05"
      },
      "source": [
        "## **Question 3:**\n",
        "\n",
        "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/).\n",
        "\n",
        "The following information of the article needs to be collected:\n",
        "\n",
        "(1) Title\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h51_PXuffzPI",
        "outputId": "7ae6cb68-a0a7-4759-de78-19ef51143d8f"
      },
      "source": [
        "# You code here (Please add comments in the code):\n",
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "\n",
        "with urllib.request.urlopen('https://api.semanticscholar.org/v1/paper/10.1145/2348283.2348407') as filein:\n",
        "    page = filein.read()\n",
        "    soup = BeautifulSoup(page)\n",
        "#     print (soup.prettify())\n",
        "    text2 = soup.p.text\n",
        "    print(text2)\n",
        "    with open('2348407-meta.txt', 'w') as fileou:\n",
        "        json.dump(text2, fileou)\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"abstract\":\"Typically, every part in most coherent text has some plausible reason for its presence, some function that it performs to the overall semantics of the text. Rhetorical relations, e.g. contrast, cause, explanation, describe how the parts of a text are linked to each other. Knowledge about this so-called discourse structure has been applied successfully to several natural language processing tasks. This work studies the use of rhetorical relations for Information Retrieval (IR): Is there a correlation between certain rhetorical relations and retrieval performance? Can knowledge about a document's rhetorical relations be useful to IR? We present a language model modification that considers rhetorical relations when estimating the relevance of a document to a query. Empirical evaluation of different versions of our model on TREC settings shows that certain rhetorical relations can benefit retrieval effectiveness notably (>10% in mean average precision over a state-of-the-art baseline).\",\"arxivId\":\"1704.01599\",\"authors\":[{\"authorId\":\"1784800\",\"name\":\"C. Lioma\",\"url\":\"https://www.semanticscholar.org/author/1784800\"},{\"authorId\":\"145216927\",\"name\":\"Birger Larsen\",\"url\":\"https://www.semanticscholar.org/author/145216927\"},{\"authorId\":null,\"name\":\"Wei Lu\",\"url\":null}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144144799\",\"name\":\"Puneet Mathur\"},{\"authorId\":null,\"name\":\"Rajiv Jain\"},{\"authorId\":\"2075390842\",\"name\":\"Franck Dernoncourt\"},{\"authorId\":\"2852035\",\"name\":\"Vlad I. Morariu\"},{\"authorId\":\"2536742\",\"name\":\"Quan Hung Tran\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":\"10.18653/v1/2021.acl-short.67\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce9e010c5cb2323dfed3af687b12875f01c759bc\",\"title\":\"TIMERS: Document-level Temporal Relation Extraction\",\"url\":\"https://www.semanticscholar.org/paper/ce9e010c5cb2323dfed3af687b12875f01c759bc\",\"venue\":\"ACL/IJCNLP\",\"year\":2021},{\"arxivId\":\"2006.00572\",\"authors\":[{\"authorId\":\"1403693098\",\"name\":\"Erfaneh Gharavi\"},{\"authorId\":\"2024809\",\"name\":\"H. Veisi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"213c505be2cc73343110fd6a41982f0ddaa2d0ee\",\"title\":\"Improve Document Embedding for Text Categorization Through Deep Siamese Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/213c505be2cc73343110fd6a41982f0ddaa2d0ee\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2021071353\",\"name\":\"B. Galitsky\"}],\"doi\":\"10.1007/978-3-030-61641-0_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91d910139cddd7acd4858dd98ccef72cacdbb644\",\"title\":\"Chatbots for CRM and Dialogue Management\",\"url\":\"https://www.semanticscholar.org/paper/91d910139cddd7acd4858dd98ccef72cacdbb644\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144264304\",\"name\":\"Boris A. Galitsky\"},{\"authorId\":\"1755765\",\"name\":\"Dmitry I. Ilvovsky\"}],\"doi\":\"10.26615/978-954-452-056-4_044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2311b92150c7b10c43d9b59348cc2ccf93da9bf2\",\"title\":\"Discourse-Based Approach to Involvement of Background Knowledge for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2311b92150c7b10c43d9b59348cc2ccf93da9bf2\",\"venue\":\"RANLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8566053\",\"name\":\"Erfaneh Gharavi\"},{\"authorId\":\"83195228\",\"name\":\"R. Silwal\"},{\"authorId\":\"2134075\",\"name\":\"M. Gerber\"},{\"authorId\":\"2024809\",\"name\":\"H. Veisi\"}],\"doi\":\"10.1109/ICOSC.2019.8665662\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31c0b55c8ba469874c4fa7b3fd8b70375b1e7421\",\"title\":\"Siamese Discourse Structure Recursive Neural Network for Semantic Representation\",\"url\":\"https://www.semanticscholar.org/paper/31c0b55c8ba469874c4fa7b3fd8b70375b1e7421\",\"venue\":\"2019 IEEE 13th International Conference on Semantic Computing (ICSC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2790926\",\"name\":\"Mrinmaya Sachan\"},{\"authorId\":\"89890133\",\"name\":\"Kumar Avinava Dubey\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"},{\"authorId\":\"40975594\",\"name\":\"Tom Michael Mitchell\"},{\"authorId\":\"144590225\",\"name\":\"D. Roth\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1162/coli_a_00360\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"710e8c7fa63104ecaf5aee2b898c0c465f82b96d\",\"title\":\"Discourse in Multimedia: A Case Study in Extracting Geometry Knowledge from Textbooks\",\"url\":\"https://www.semanticscholar.org/paper/710e8c7fa63104ecaf5aee2b898c0c465f82b96d\",\"venue\":\"Computational Linguistics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144264304\",\"name\":\"Boris A. Galitsky\"}],\"doi\":\"10.1007/978-3-030-04299-8_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7bb0bafea9a8e9ee177ddf6fa116d1b3b9ae9a89\",\"title\":\"Discourse-Level Dialogue Management\",\"url\":\"https://www.semanticscholar.org/paper/7bb0bafea9a8e9ee177ddf6fa116d1b3b9ae9a89\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2790926\",\"name\":\"Mrinmaya Sachan\"},{\"authorId\":\"89890133\",\"name\":\"Kumar Avinava Dubey\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"},{\"authorId\":\"40975594\",\"name\":\"Tom Michael Mitchell\"},{\"authorId\":\"144590225\",\"name\":\"D. Roth\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1162/COLI_a_00360\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3722832c69a6e6e42fc314ec3feb56e18b5b51f\",\"title\":\"Discourse in Multimedia: A Case Study in Extracting Geometry Knowledge from Textbooks\",\"url\":\"https://www.semanticscholar.org/paper/c3722832c69a6e6e42fc314ec3feb56e18b5b51f\",\"venue\":\"Computational Linguistics\",\"year\":2019},{\"arxivId\":\"1811.05546\",\"authors\":[{\"authorId\":\"2790926\",\"name\":\"Mrinmaya Sachan\"},{\"authorId\":\"89890133\",\"name\":\"Kumar Avinava Dubey\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"},{\"authorId\":\"40975594\",\"name\":\"Tom Michael Mitchell\"},{\"authorId\":\"144590225\",\"name\":\"D. Roth\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"56e13ac67e383b80896436122cce5a34617a9513\",\"title\":\"Discourse in Multimedia: A Case Study in Information Extraction\",\"url\":\"https://www.semanticscholar.org/paper/56e13ac67e383b80896436122cce5a34617a9513\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1413101320\",\"name\":\"Lin Chuan-An\"},{\"authorId\":\"2611607\",\"name\":\"Hen-Hsen Huang\"},{\"authorId\":\"8157332\",\"name\":\"Zi-Yuan Chen\"},{\"authorId\":\"153924342\",\"name\":\"Hsin-Hsi Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7d77615ace68f881a5db6db50b45cb0f8da465c\",\"title\":\"A Unified RvNN Framework for End-to-End Chinese Discourse Parsing\",\"url\":\"https://www.semanticscholar.org/paper/f7d77615ace68f881a5db6db50b45cb0f8da465c\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143828316\",\"name\":\"Liana Ermakova\"},{\"authorId\":\"1707022\",\"name\":\"J. Mothe\"},{\"authorId\":\"143709239\",\"name\":\"A. Firsov\"}],\"doi\":\"10.1145/3077136.3080720\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"19f11641dc8f1ede579ca4e7f212b96d2a8c607f\",\"title\":\"A Metric for Sentence Ordering Assessment Based on Topic-Comment Structure\",\"url\":\"https://www.semanticscholar.org/paper/19f11641dc8f1ede579ca4e7f212b96d2a8c607f\",\"venue\":\"SIGIR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2072910756\",\"name\":\"V\\u00edctor Flores\"},{\"authorId\":\"2098570488\",\"name\":\"Yahima Hadfeg\"},{\"authorId\":\"2385175\",\"name\":\"C. Villegas\"}],\"doi\":\"10.1007/978-3-319-60837-2_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ec8e675d1ff640e4828e174a54e2beaec3679e6\",\"title\":\"Generating Natural Language Explanations from Knowledge-Based Systems Results, Using Ontology and Discourses Patterns\",\"url\":\"https://www.semanticscholar.org/paper/3ec8e675d1ff640e4828e174a54e2beaec3679e6\",\"venue\":\"IJCRS\",\"year\":2017},{\"arxivId\":\"1703.03640\",\"authors\":[{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"3018458\",\"name\":\"Niels Dalum Hansen\"}],\"doi\":\"10.1016/j.cogsys.2017.03.001\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"478adb395044b5d9b4039b9a80963b151446cdab\",\"title\":\"A study of metrics of distance and correlation between ranked lists for compositionality detection\",\"url\":\"https://www.semanticscholar.org/paper/478adb395044b5d9b4039b9a80963b151446cdab\",\"venue\":\"Cognitive Systems Research\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143828316\",\"name\":\"Liana Ermakova\"},{\"authorId\":\"1707022\",\"name\":\"J. Mothe\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5af0f4536f8a98d7e42a40be3fd0e5e51c08d166\",\"title\":\"La structure th\\u00e8me-rh\\u00e8me pour l'ordonnancement de documents en recherche d'information\",\"url\":\"https://www.semanticscholar.org/paper/5af0f4536f8a98d7e42a40be3fd0e5e51c08d166\",\"venue\":\"Document Num\\u00e9rique\",\"year\":2017},{\"arxivId\":\"1709.03742\",\"authors\":[{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8ff7f47ef653603b6f65c128627c280ca1026dba\",\"title\":\"Dependencies: Formalising Semantic Catenae for Information Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/8ff7f47ef653603b6f65c128627c280ca1026dba\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143828316\",\"name\":\"Liana Ermakova\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0b9d7421cec8448b0ca96d74cefab96c25d29a1c\",\"title\":\"Short text contextualization in information retrieval : application to tweet contextualization and automatic query expansion. (Contextualisation de textes courts pour la recherche d'information : application \\u00e0 la contextualisation de tweets et \\u00e0 l'expansion automatique de requ\\u00eates)\",\"url\":\"https://www.semanticscholar.org/paper/0b9d7421cec8448b0ca96d74cefab96c25d29a1c\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143828316\",\"name\":\"Liana Ermakova\"},{\"authorId\":\"1707022\",\"name\":\"J. Mothe\"}],\"doi\":\"10.1109/RCIS.2016.7549352\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c4c5d3c9ba58c7e0aadcca70c0771a662ca97dd\",\"title\":\"Document re-ranking based on topic-comment structure\",\"url\":\"https://www.semanticscholar.org/paper/1c4c5d3c9ba58c7e0aadcca70c0771a662ca97dd\",\"venue\":\"2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS)\",\"year\":2016},{\"arxivId\":\"1608.00758\",\"authors\":[{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"1724314\",\"name\":\"Fabien Tarissan\"},{\"authorId\":\"1707651\",\"name\":\"J. Simonsen\"},{\"authorId\":\"8304471\",\"name\":\"C. Petersen\"},{\"authorId\":\"145216927\",\"name\":\"Birger Larsen\"}],\"doi\":\"10.1145/2970398.2970413\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e45b7dbe1f12ea0110fa5bb7609aa90b33c20d9\",\"title\":\"Exploiting the Bipartite Structure of Entity Grids for Document Coherence and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/3e45b7dbe1f12ea0110fa5bb7609aa90b33c20d9\",\"venue\":\"ICTIR\",\"year\":2016},{\"arxivId\":\"1610.01327\",\"authors\":[{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"145216927\",\"name\":\"Birger Larsen\"},{\"authorId\":null,\"name\":\"Wei Lu\"},{\"authorId\":\"48356012\",\"name\":\"Y. Huang\"}],\"doi\":\"10.1145/3006299.3006315\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8064f19f6f07e471a5ed84e3e862ab9b0763185a\",\"title\":\"A study of factuality, objectivity and relevance: three desiderata in large-scale information retrieval?\",\"url\":\"https://www.semanticscholar.org/paper/8064f19f6f07e471a5ed84e3e862ab9b0763185a\",\"venue\":\"BDCAT\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1707022\",\"name\":\"J. Mothe\"},{\"authorId\":\"3162238\",\"name\":\"Marion Moulinou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8a73852122c71aad778993222766c6f4dd740fd6\",\"title\":\"Analyse des param\\u00e8tres de recherche d'information: Etude de l'influence des param\\u00e8tres sur les r\\u00e9sultats\",\"url\":\"https://www.semanticscholar.org/paper/8a73852122c71aad778993222766c6f4dd740fd6\",\"venue\":\"EGC\",\"year\":2015},{\"arxivId\":\"1507.08234\",\"authors\":[{\"authorId\":\"8304471\",\"name\":\"C. Petersen\"},{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"1707651\",\"name\":\"J. Simonsen\"},{\"authorId\":\"145216927\",\"name\":\"Birger Larsen\"}],\"doi\":\"10.1145/2808194.2809458\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e9cb0f457cc8ff9c56b92b96e2e14565feb56552\",\"title\":\"Entropy and Graph Based Modelling of Document Coherence using Discourse Entities: An Application to IR\",\"url\":\"https://www.semanticscholar.org/paper/e9cb0f457cc8ff9c56b92b96e2e14565feb56552\",\"venue\":\"ICTIR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2762285\",\"name\":\"Jos\\u00e9 M. Chenlo\"},{\"authorId\":\"1788721\",\"name\":\"A. Hogenboom\"},{\"authorId\":\"2356644\",\"name\":\"D. Losada\"}],\"doi\":\"10.1016/j.datak.2014.07.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6007af381e860f920fc05401fe826c67c6f2b18a\",\"title\":\"Rhetorical Structure Theory for polarity estimation: An experimental study\",\"url\":\"https://www.semanticscholar.org/paper/6007af381e860f920fc05401fe826c67c6f2b18a\",\"venue\":\"Data Knowl. Eng.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"133998176\",\"name\":\"Gonz\\u00e1lez Chenlo\"},{\"authorId\":\"143697792\",\"name\":\"J. Manuel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd2426c0f4fd14a2a061662a2074b52bcd3f06bb\",\"title\":\"Exploiting multiple sources of evidence for opinion search in the web\",\"url\":\"https://www.semanticscholar.org/paper/bd2426c0f4fd14a2a061662a2074b52bcd3f06bb\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14201699\",\"name\":\"Sungbin Choi\"},{\"authorId\":\"4273555\",\"name\":\"Jinwook Choi\"},{\"authorId\":\"34786903\",\"name\":\"Sooyoung Yoo\"},{\"authorId\":\"2108878965\",\"name\":\"Heechun Kim\"},{\"authorId\":\"2110076700\",\"name\":\"Youngho Lee\"}],\"doi\":\"10.1016/j.jbi.2013.08.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7181bd11fa61899b3ccd4c7f527de0eb6244913\",\"title\":\"Semantic concept-enriched dependence model for medical information retrieval\",\"url\":\"https://www.semanticscholar.org/paper/c7181bd11fa61899b3ccd4c7f527de0eb6244913\",\"venue\":\"J. Biomed. Informatics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48969078\",\"name\":\"W. Drijfhout\"},{\"authorId\":\"2327920\",\"name\":\"O. Jundt\"},{\"authorId\":\"2911513\",\"name\":\"L. Wevers\"},{\"authorId\":\"1691929\",\"name\":\"D. Hiemstra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10ca1c847a200f46c969261d3686f7be136c7bef\",\"title\":\"Traitor: Associating Concepts using the World Wide Web\",\"url\":\"https://www.semanticscholar.org/paper/10ca1c847a200f46c969261d3686f7be136c7bef\",\"venue\":\"DIR\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127495\",\"name\":\"Fawaz Alarfaj\"},{\"authorId\":\"2993548\",\"name\":\"Udo Kruschwitz\"},{\"authorId\":\"144251978\",\"name\":\"C. Fox\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3aa86dcc5c2b83e7a39481dd729f07e9eb90c87c\",\"title\":\"An Adaptive Window-Size Approach for Expert-Finding\",\"url\":\"https://www.semanticscholar.org/paper/3aa86dcc5c2b83e7a39481dd729f07e9eb90c87c\",\"venue\":\"DIR\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34805599\",\"name\":\"Kurt Englmeier\"},{\"authorId\":\"35263108\",\"name\":\"J. Atkinson\"},{\"authorId\":\"1707022\",\"name\":\"J. Mothe\"},{\"authorId\":\"48821339\",\"name\":\"F. Murtagh\"},{\"authorId\":\"145433861\",\"name\":\"J. Pereira\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c844ff5f73186762d70cfa0247ffd90ac582860\",\"title\":\"Open Archive TOULOUSE Archive Ouverte (OATAO)\",\"url\":\"https://www.semanticscholar.org/paper/3c844ff5f73186762d70cfa0247ffd90ac582860\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2762285\",\"name\":\"Jos\\u00e9 M. Chenlo\"},{\"authorId\":\"1788721\",\"name\":\"A. Hogenboom\"},{\"authorId\":\"2356644\",\"name\":\"D. Losada\"}],\"doi\":\"10.1007/978-3-642-38824-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5550303aab415c066964738e32bc7076209ba4ad\",\"title\":\"Sentiment-Based Ranking of Blog Posts Using Rhetorical Structure Theory\",\"url\":\"https://www.semanticscholar.org/paper/5550303aab415c066964738e32bc7076209ba4ad\",\"venue\":\"NLDB\",\"year\":2013}],\"corpusId\":7087061,\"doi\":\"10.1145/2348283.2348407\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"isOpenAccess\":true,\"isPublisherLicensed\":true,\"is_open_access\":true,\"is_publisher_licensed\":true,\"numCitedBy\":28,\"numCiting\":40,\"paperId\":\"4c64daac9dda2920752e9a2b0333abe3e02f4beb\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1695153\",\"name\":\"W. Mann\"},{\"authorId\":\"20082155\",\"name\":\"S. A. Thompson\"}],\"doi\":\"10.1515/text.1.1988.8.3.243\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"af5100605a3b6bfd0adf9a30e69a47d1b98340ba\",\"title\":\"Rhetorical Structure Theory: Toward a functional theory of text organization\",\"url\":\"https://www.semanticscholar.org/paper/af5100605a3b6bfd0adf9a30e69a47d1b98340ba\",\"venue\":\"\",\"year\":1988},{\"arxivId\":\"1302.6782\",\"authors\":[{\"authorId\":\"1406721516\",\"name\":\"Adriano Azevedo-Filho\"},{\"authorId\":\"2932960\",\"name\":\"R. Shachter\"}],\"doi\":\"10.1016/B978-1-55860-332-5.50009-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d7a296a0b0210be84934120396a41b7f7b2c25f\",\"title\":\"Laplace's Method Approximations for Probabilistic Inference in Belief Networks with Continuous Variables\",\"url\":\"https://www.semanticscholar.org/paper/7d7a296a0b0210be84934120396a41b7f7b2c25f\",\"venue\":\"UAI\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34938639\",\"name\":\"W. A. Gale\"},{\"authorId\":\"3215185\",\"name\":\"G. Sampson\"}],\"doi\":\"10.1080/09296179508590051\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"cddeb5149f4de157d4daeb609a8b1432a8126e7b\",\"title\":\"Good-Turing Frequency Estimation Without Tears\",\"url\":\"https://www.semanticscholar.org/paper/cddeb5149f4de157d4daeb609a8b1432a8126e7b\",\"venue\":\"J. Quant. Linguistics\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749837\",\"name\":\"Eugene Charniak\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76d5e3fa888bee872b7adb7fa810089aa8ab1d58\",\"title\":\"A Maximum-Entropy-Inspired Parser\",\"url\":\"https://www.semanticscholar.org/paper/76d5e3fa888bee872b7adb7fa810089aa8ab1d58\",\"venue\":\"ANLP\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1793218\",\"name\":\"D. Gildea\"},{\"authorId\":\"1746807\",\"name\":\"Dan Jurafsky\"}],\"doi\":\"10.3115/1075218.1075283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c274b8aac56e49e65a3827c570b2496b14429166\",\"title\":\"Automatic Labeling of Semantic Roles\",\"url\":\"https://www.semanticscholar.org/paper/c274b8aac56e49e65a3827c570b2496b14429166\",\"venue\":\"ACL\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12303693\",\"name\":\"Lynn Carlson\"},{\"authorId\":\"1695463\",\"name\":\"D. Marcu\"},{\"authorId\":\"7424872\",\"name\":\"Mary Ellen Okurovsky\"}],\"doi\":\"10.3115/1118078.1118083\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"07a78850c0c2ff11acf21fccca40bfcb79da282b\",\"title\":\"Building a Discourse-Tagged Corpus in the Framework of Rhetorical Structure Theory\",\"url\":\"https://www.semanticscholar.org/paper/07a78850c0c2ff11acf21fccca40bfcb79da282b\",\"venue\":\"SIGDIAL Workshop\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"2352980\",\"name\":\"T. Rath\"},{\"authorId\":\"2709427\",\"name\":\"Fangfang Feng\"}],\"doi\":\"10.1145/383952.384005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67cb24c172b66b2d14f066a1f02ce57a22a075a1\",\"title\":\"Modeling score distributions for combining the outputs of search engines\",\"url\":\"https://www.semanticscholar.org/paper/67cb24c172b66b2d14f066a1f02ce57a22a075a1\",\"venue\":\"SIGIR '01\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2480901\",\"name\":\"S. Teufel\"},{\"authorId\":\"2085030\",\"name\":\"M. Moens\"}],\"doi\":\"10.1162/089120102762671936\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"54eafbf7621337724c6591cc13e604986243293a\",\"title\":\"Summarizing Scientific Articles: Experiments with Relevance and Rhetorical Status\",\"url\":\"https://www.semanticscholar.org/paper/54eafbf7621337724c6591cc13e604986243293a\",\"venue\":\"Computational Linguistics\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2768186\",\"name\":\"K. J\\u00e4rvelin\"},{\"authorId\":\"2732839\",\"name\":\"Jaana Kek\\u00e4l\\u00e4inen\"}],\"doi\":\"10.1145/582415.582418\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8490234d79b47e459824dcf87c1e288211a3c964\",\"title\":\"Cumulated gain-based evaluation of IR techniques\",\"url\":\"https://www.semanticscholar.org/paper/8490234d79b47e459824dcf87c1e288211a3c964\",\"venue\":\"TOIS\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2912454\",\"name\":\"C. Fillmore\"},{\"authorId\":\"1749194\",\"name\":\"C. Baker\"},{\"authorId\":\"153515478\",\"name\":\"H. Sato\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87834ded1d151355d2028dc6efb26fcaa48ab9fc\",\"title\":\"The FrameNet Database and Software Tools\",\"url\":\"https://www.semanticscholar.org/paper/87834ded1d151355d2028dc6efb26fcaa48ab9fc\",\"venue\":\"LREC\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736467\",\"name\":\"ChengXiang Zhai\"},{\"authorId\":\"1739581\",\"name\":\"J. Lafferty\"}],\"doi\":\"10.1145/564376.564387\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"decf799682a402b9ee50b9d6c0267f6c545a7031\",\"title\":\"Two-stage language models for information retrieval\",\"url\":\"https://www.semanticscholar.org/paper/decf799682a402b9ee50b9d6c0267f6c545a7031\",\"venue\":\"SIGIR '02\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144156677\",\"name\":\"Paul Kingsbury\"},{\"authorId\":\"145755155\",\"name\":\"Martha Palmer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc090a68e45e0e6337136777d21c87b76a90ae72\",\"title\":\"From TreeBank to PropBank\",\"url\":\"https://www.semanticscholar.org/paper/fc090a68e45e0e6337136777d21c87b76a90ae72\",\"venue\":\"LREC\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"},{\"authorId\":\"1695463\",\"name\":\"D. Marcu\"}],\"doi\":\"10.3115/1073445.1073475\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0b3858c0c31c6f0826c891a42367671f6e76d46c\",\"title\":\"Sentence Level Discourse Parsing using Syntactic and Lexical Information\",\"url\":\"https://www.semanticscholar.org/paper/0b3858c0c31c6f0826c891a42367671f6e76d46c\",\"venue\":\"NAACL\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144456145\",\"name\":\"W. Croft\"},{\"authorId\":\"1739581\",\"name\":\"J. Lafferty\"}],\"doi\":\"10.1007/978-94-017-0171-6\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b71ead55fd6520dd4604de66cbb732bc2b7a6070\",\"title\":\"Language Modeling for Information Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/b71ead55fd6520dd4604de66cbb732bc2b7a6070\",\"venue\":\"The Springer International Series on Information Retrieval\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12294213\",\"name\":\"J. Morato\"},{\"authorId\":\"3028529\",\"name\":\"J. Morillo\"},{\"authorId\":\"1805316\",\"name\":\"Gonzalo G\\u00e9nova\"},{\"authorId\":\"31513219\",\"name\":\"Jos\\u00e9 A. Moreiro\"}],\"doi\":\"10.1016/S0306-4573(02)00081-X\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb38a830255783ad3f0824d15f178dd03e5e2be2\",\"title\":\"Experiments in discourse analysis impact on information classification and retrieval algorithms\",\"url\":\"https://www.semanticscholar.org/paper/cb38a830255783ad3f0824d15f178dd03e5e2be2\",\"venue\":\"Inf. Process. Manag.\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144009691\",\"name\":\"Chris Buckley\"},{\"authorId\":\"1746656\",\"name\":\"E. Voorhees\"}],\"doi\":\"10.1145/1008992.1009000\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6878cdc5b632e018f827a9d1520e7353d8502d25\",\"title\":\"Retrieval evaluation with incomplete information\",\"url\":\"https://www.semanticscholar.org/paper/6878cdc5b632e018f827a9d1520e7353d8502d25\",\"venue\":\"SIGIR '04\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49370744\",\"name\":\"D. Y. Wang\"},{\"authorId\":\"1752375\",\"name\":\"R. Luk\"},{\"authorId\":\"1784988\",\"name\":\"K. Wong\"},{\"authorId\":\"145219946\",\"name\":\"K. Kwok\"}],\"doi\":\"10.1007/11765448_18\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6dcfcc8c5486859d78e317896abad0c4314442c\",\"title\":\"An Information Retrieval Approach Based on Discourse Type\",\"url\":\"https://www.semanticscholar.org/paper/e6dcfcc8c5486859d78e317896abad0c4314442c\",\"venue\":\"NLDB\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46611104\",\"name\":\"M. Sun\"},{\"authorId\":\"1707259\",\"name\":\"J. Y. Chai\"}],\"doi\":\"10.1016/j.knosys.2007.04.005\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"525867ebf15c535305f18eeb12b41b5d71168abf\",\"title\":\"Discourse processing for context question answering based on linguistic knowledge\",\"url\":\"https://www.semanticscholar.org/paper/525867ebf15c535305f18eeb12b41b5d71168abf\",\"venue\":\"Knowl. Based Syst.\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30184027\",\"name\":\"B. Webber\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"31793f9f959ac175632407ab0d9b7bda0e32f6f3\",\"title\":\"Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2 - Volume 2\",\"url\":\"https://www.semanticscholar.org/paper/31793f9f959ac175632407ab0d9b7bda0e32f6f3\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2800288\",\"name\":\"David duVerle\"},{\"authorId\":\"2356111\",\"name\":\"H. Prendinger\"}],\"doi\":\"10.3115/1690219.1690239\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7cc84d84ad87b9a1f6496fb4acbbc758a9be6345\",\"title\":\"A Novel Discourse Parser Based on Support Vector Machine Classification\",\"url\":\"https://www.semanticscholar.org/paper/7cc84d84ad87b9a1f6496fb4acbbc758a9be6345\",\"venue\":\"ACL\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2059584\",\"name\":\"Swapna Somasundaran\"},{\"authorId\":\"1686834\",\"name\":\"Galileo Namata\"},{\"authorId\":\"144120827\",\"name\":\"J. Wiebe\"},{\"authorId\":\"1746034\",\"name\":\"L. Getoor\"}],\"doi\":\"10.3115/1699510.1699533\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9bd67cc94aa20fec80b205ee75517a4f194adc9c\",\"title\":\"Supervised and Unsupervised Methods in Employing Discourse Relations for Improving Opinion Polarity Classification\",\"url\":\"https://www.semanticscholar.org/paper/9bd67cc94aa20fec80b205ee75517a4f194adc9c\",\"venue\":\"EMNLP\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756567\",\"name\":\"L. Yu\"},{\"authorId\":\"1681512\",\"name\":\"Chung-Hsien Wu\"},{\"authorId\":\"3008622\",\"name\":\"F. Jang\"}],\"doi\":\"10.1016/j.artint.2008.12.004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbfcb90cda0999a56a6d13bcac84f12adf0d2436\",\"title\":\"Psychiatric document retrieval using a discourse-aware model\",\"url\":\"https://www.semanticscholar.org/paper/cbfcb90cda0999a56a6d13bcac84f12adf0d2436\",\"venue\":\"Artif. Intell.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2160529\",\"name\":\"Daniel Tunkelang\"},{\"authorId\":\"1701298\",\"name\":\"M. Thelwall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d07576c370cc6ef48f9268714b4fd1c75b226ef5\",\"title\":\"Synthesis Lectures on Information Concepts, Retrieval, and Services\",\"url\":\"https://www.semanticscholar.org/paper/d07576c370cc6ef48f9268714b4fd1c75b226ef5\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689089\",\"name\":\"M. Smucker\"},{\"authorId\":\"144890574\",\"name\":\"James Allan\"},{\"authorId\":\"1750995\",\"name\":\"Ben Carterette\"}],\"doi\":\"10.1145/1571941.1572050\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e38cde98f2e2012ee848bab4a3c964624783be7d\",\"title\":\"Agreement among statistical significance tests for information retrieval evaluation at varying sample sizes\",\"url\":\"https://www.semanticscholar.org/paper/e38cde98f2e2012ee848bab4a3c964624783be7d\",\"venue\":\"SIGIR\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39055225\",\"name\":\"J. Wang\"},{\"authorId\":\"39522749\",\"name\":\"Jianhan Zhu\"}],\"doi\":\"10.1145/1835449.1835489\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34b6e6f0187f2cd44eeca1b80da464562357b20a\",\"title\":\"On statistical analysis and optimization of information retrieval effectiveness metrics\",\"url\":\"https://www.semanticscholar.org/paper/34b6e6f0187f2cd44eeca1b80da464562357b20a\",\"venue\":\"SIGIR\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50649676\",\"name\":\"J. Clarke\"},{\"authorId\":\"1747893\",\"name\":\"Mirella Lapata\"}],\"doi\":\"10.1162/coli_a_00004\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"6c95908d08323c5acfc5bfdf7399f31563ade4f5\",\"title\":\"Discourse Constraints for Document Compression\",\"url\":\"https://www.semanticscholar.org/paper/6c95908d08323c5acfc5bfdf7399f31563ade4f5\",\"venue\":\"CL\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1767336\",\"name\":\"Annie Louis\"},{\"authorId\":\"1714374\",\"name\":\"A. Joshi\"},{\"authorId\":\"3115414\",\"name\":\"A. Nenkova\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b88876344be6d9a8172f72bc0a836994f6b6f719\",\"title\":\"Discourse indicators for content selection in summarization\",\"url\":\"https://www.semanticscholar.org/paper/b88876344be6d9a8172f72bc0a836994f6b6f719\",\"venue\":\"SIGDIAL Conference\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9106864\",\"name\":\"Nipun Suwandaratna\"},{\"authorId\":\"39630485\",\"name\":\"U. Perera\"}],\"doi\":\"10.1109/ICIAFS.2010.5715646\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c43f79ab60afc1e2bc3859365c120eb11bd0bbd7\",\"title\":\"Discourse marker based topic identification and search results refining\",\"url\":\"https://www.semanticscholar.org/paper/c43f79ab60afc1e2bc3859365c120eb11bd0bbd7\",\"venue\":\"2010 Fifth International Conference on Information and Automation for Sustainability\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1815447\",\"name\":\"Michael Bendersky\"},{\"authorId\":\"144456145\",\"name\":\"W. Croft\"},{\"authorId\":\"1891854\",\"name\":\"Y. Diao\"}],\"doi\":\"10.1145/1935826.1935849\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08c34883743406f05a10c54c802373997c706ce7\",\"title\":\"Quality-biased ranking of web documents\",\"url\":\"https://www.semanticscholar.org/paper/08c34883743406f05a10c54c802373997c706ce7\",\"venue\":\"WSDM '11\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1893187\",\"name\":\"Eyal Krikon\"},{\"authorId\":\"1779654\",\"name\":\"Oren Kurland\"}],\"doi\":\"10.1007/s10791-011-9168-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"278f55438b8fa2eb3cea6a120d48ea1f8b8b07f9\",\"title\":\"A study of the integration of passage-, document-, and cluster-based information for re-ranking search results\",\"url\":\"https://www.semanticscholar.org/paper/278f55438b8fa2eb3cea6a120d48ea1f8b8b07f9\",\"venue\":\"Information Retrieval\",\"year\":2011},{\"arxivId\":\"1004.5168\",\"authors\":[{\"authorId\":\"3114123\",\"name\":\"G. Cormack\"},{\"authorId\":\"1689089\",\"name\":\"M. Smucker\"},{\"authorId\":\"1751287\",\"name\":\"C. Clarke\"}],\"doi\":\"10.1007/s10791-011-9162-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"38612e346fdf3158c32c16058f7e8820a8f0325e\",\"title\":\"Efficient and effective spam filtering and re-ranking for large web datasets\",\"url\":\"https://www.semanticscholar.org/paper/38612e346fdf3158c32c16058f7e8820a8f0325e\",\"venue\":\"Information Retrieval\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2325985\",\"name\":\"M. Auli\"},{\"authorId\":\"144871732\",\"name\":\"A. Lopez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"889b2925ae0966585b8da6f678526bbdd99da592\",\"title\":\"Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/889b2925ae0966585b8da6f678526bbdd99da592\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1801153\",\"name\":\"Bas Heerschop\"},{\"authorId\":\"2373094\",\"name\":\"F. Goossen\"},{\"authorId\":\"1788721\",\"name\":\"A. Hogenboom\"},{\"authorId\":\"1729599\",\"name\":\"F. Frasincar\"},{\"authorId\":\"1678244\",\"name\":\"U. Kaymak\"},{\"authorId\":\"144097974\",\"name\":\"F. D. Jong\"}],\"doi\":\"10.1145/2063576.2063730\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ba847377b1667add27eb9663aa847b53c59f9aa\",\"title\":\"Polarity analysis of texts using discourse structure\",\"url\":\"https://www.semanticscholar.org/paper/9ba847377b1667add27eb9663aa847b53c59f9aa\",\"venue\":\"CIKM '11\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2718039\",\"name\":\"Christos Christodoulopoulos\"},{\"authorId\":\"1991315\",\"name\":\"S. Goldwater\"},{\"authorId\":\"145332819\",\"name\":\"Mark Steedman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6b2694d5606a0bbab63c4c470b20f1b754df9ff\",\"title\":\"Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, EMNLP 2011, 27-31 July 2011, John McIntyre Conference Centre, Edinburgh, UK, A meeting of SIGDAT, a Special Interest Group of the ACL\",\"url\":\"https://www.semanticscholar.org/paper/a6b2694d5606a0bbab63c4c470b20f1b754df9ff\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48169566\",\"name\":\"L. Wang\"},{\"authorId\":\"5571580\",\"name\":\"Marco Lui\"},{\"authorId\":\"1736741380\",\"name\":\"Su Nam Kim\"},{\"authorId\":\"1720988\",\"name\":\"Joakim Nivre\"},{\"authorId\":\"145465286\",\"name\":\"Timothy Baldwin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d471854ae1705a5e4f6df60ec8fb602c6e88b673\",\"title\":\"Predicting Thread Discourse Structure over Technical Web Forums\",\"url\":\"https://www.semanticscholar.org/paper/d471854ae1705a5e4f6df60ec8fb602c6e88b673\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701219\",\"name\":\"Sucheta Ghosh\"},{\"authorId\":\"145341661\",\"name\":\"Richard Johansson\"},{\"authorId\":\"1719162\",\"name\":\"G. Riccardi\"},{\"authorId\":\"1809243\",\"name\":\"Sara Tonelli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2b168dbaa57736b31891451163a5c5582d84324\",\"title\":\"Shallow Discourse Parsing with Conditional Random Fields\",\"url\":\"https://www.semanticscholar.org/paper/e2b168dbaa57736b31891451163a5c5582d84324\",\"venue\":\"IJCNLP\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2204295\",\"name\":\"Lanjun Zhou\"},{\"authorId\":\"1707937\",\"name\":\"Binyang Li\"},{\"authorId\":\"145816335\",\"name\":\"Wei Gao\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"1784988\",\"name\":\"Kam-Fai Wong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5cb9f31922d4381a8b326b9cd9cbdacf744907c\",\"title\":\"Unsupervised Discovery of Discourse Relations for Eliminating Intra-sentence Polarity Ambiguities\",\"url\":\"https://www.semanticscholar.org/paper/e5cb9f31922d4381a8b326b9cd9cbdacf744907c\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36717818\",\"name\":\"A. Davison\"}],\"doi\":\"10.1007/978-1-4614-6170-8_100159\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1be08088b4ca2a3d214cbbb325fbde30c334a77e\",\"title\":\"Statistical Models\",\"url\":\"https://www.semanticscholar.org/paper/1be08088b4ca2a3d214cbbb325fbde30c334a77e\",\"venue\":\"Encyclopedia of Social Network Analysis and Mining\",\"year\":2014}],\"title\":\"Rhetorical relations for information retrieval\",\"topics\":[{\"topic\":\"Information retrieval\",\"topicId\":\"2867\",\"url\":\"https://www.semanticscholar.org/topic/2867\"},{\"topic\":\"Natural language processing\",\"topicId\":\"1914\",\"url\":\"https://www.semanticscholar.org/topic/1914\"},{\"topic\":\"Language model\",\"topicId\":\"26812\",\"url\":\"https://www.semanticscholar.org/topic/26812\"},{\"topic\":\"Linker (computing)\",\"topicId\":\"25565\",\"url\":\"https://www.semanticscholar.org/topic/25565\"},{\"topic\":\"Relevance\",\"topicId\":\"503\",\"url\":\"https://www.semanticscholar.org/topic/503\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Coherence (physics)\",\"topicId\":\"921\",\"url\":\"https://www.semanticscholar.org/topic/921\"}],\"url\":\"https://www.semanticscholar.org/paper/4c64daac9dda2920752e9a2b0333abe3e02f4beb\",\"venue\":\"SIGIR '12\",\"year\":2012}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fyr8mfCgAm2"
      },
      "source": [
        "## **Question 4:** (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data.\n",
        "\n",
        "The following information needs to be collected:\n",
        "\n",
        "(1) User_name\n",
        "\n",
        "(2) Posted time\n",
        "\n",
        "(3) Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMZc7kK0gJkD",
        "outputId": "82c98236-353e-444f-ec24-40a25857f6a3"
      },
      "source": [
        "!pip install GetOldTweets3"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting GetOldTweets3\n",
            "  Downloading GetOldTweets3-0.0.11-py3-none-any.whl (13 kB)\n",
            "Collecting pyquery>=1.2.10\n",
            "  Downloading pyquery-1.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from GetOldTweets3) (4.2.6)\n",
            "Collecting cssselect>0.7.9\n",
            "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: cssselect, pyquery, GetOldTweets3\n",
            "Successfully installed GetOldTweets3-0.0.11 cssselect-1.1.0 pyquery-1.4.3\n"
          ]
        }
      ]
    }
  ]
}